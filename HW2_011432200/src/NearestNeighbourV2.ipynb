{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import scipy as sp\n",
    "from scipy import spatial\n",
    "\n",
    "import matplotlib.pyplot as plt # side-stepping mpl backend\n",
    "\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import pairwise\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn import cross_validation\n",
    "import heapq\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "st = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18506\n",
      "6\n",
      "18506\n"
     ]
    }
   ],
   "source": [
    "with open(\"TestData/train.dat\", \"r\") as fh:\n",
    "    #with open(\"TestData/Test/training_out.dat\", \"r\") as fh:\n",
    "    linesOfTrainData = fh.readlines()\n",
    "print(len(linesOfTrainData))\n",
    "\n",
    "#with open(\"TestData/format.dat\", \"r\") as fh:\n",
    "with open(\"TestData/Test/format_out.dat\", \"r\") as fh:\n",
    "    linesOfFormat = fh.readlines()\n",
    "print(len(linesOfFormat))\n",
    "\n",
    "with open(\"TestData/test.dat\", \"r\") as fh:\n",
    "#with open(\"TestData/Test/test_out.dat\", \"r\") as fh:\n",
    "    linesOfTestData = fh.readlines()\n",
    "print(len(linesOfTestData))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First line before cleanup from Training Data:  +1\tThis book is such a life saver.  It has been so helpful to be able to go back to track trends, answer pediatrician questions, or communicate with each other when you are up at different times of the night with a newborn.  I think it is one of those things that everyone should be required to have before they leave the hospital.  We went through all the pages of the newborn version, then moved to the infant version, and will finish up the second infant book (third total) right as our baby turns 1.  See other things that are must haves for baby at [...]\n",
      "\n",
      "\n",
      "\n",
      "First line after cleanup from Training Data:  +1\tthi book lif saver.  help abl go back track trends, answ pedy questions, commun diff tim night newborn.  think on thing everyon requir leav hospital.  went pag newborn version, mov inf version, fin second inf book (third total) right baby turn 1.  see thing must hav baby [...]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##stopwords and stemming for Training\n",
    "\n",
    "print (\"First line before cleanup from Training Data: \",linesOfTrainData[0])\n",
    "\n",
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "linesOfTrainDataAfterPreProcessing=[]\n",
    "for line in linesOfTrainData:\n",
    "    newLine = line\n",
    "    for w in newLine.split():\n",
    "        if w.lower() in stops:\n",
    "            newLine = newLine.replace(' '+w+' ', ' ') # for identifting words\n",
    "    linesOfTrainDataAfterPreProcessing.append(newLine)\n",
    "\n",
    "\n",
    "linesOfTrainDataAfterSteming = []\n",
    "for line in linesOfTrainDataAfterPreProcessing:\n",
    "    newLine = line\n",
    "    for w in newLine.split():\n",
    "            newLine = newLine.replace(w, st.stem(w)) # for stemming\n",
    "    linesOfTrainDataAfterSteming.append(newLine)\n",
    "\n",
    "linesOfTrainData = linesOfTrainDataAfterSteming\n",
    "\n",
    "print (\"\\n\\nFirst line after cleanup from Training Data: \",linesOfTrainData[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First line before cleanup from Test Data:  Perfect for new parents. We were able to keep track of baby's feeding, sleep and diaper change schedule for the first two and a half months of her life. Made life easier when the doctor would ask questions about habits because we had it all right there!\n",
      "\n",
      "\n",
      "\n",
      "First line after cleanup from Test Data:  perfect new parents. abl keep track baby's feeding, sleep diap chang schedule first two half month lif. mad lif easy doct would ask quest habit right there!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##stopwords and stemming for Testdata\n",
    "\n",
    "print (\"First line before cleanup from Test Data: \",linesOfTestData[0])\n",
    "\n",
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "linesOfTestDataAfterPreProcessing=[]\n",
    "for line in linesOfTestData:\n",
    "    newLine = line\n",
    "    for w in newLine.split():\n",
    "        if w.lower() in stops:\n",
    "            newLine = newLine.replace(' '+w+' ', ' ') # for identifting words\n",
    "    linesOfTestDataAfterPreProcessing.append(newLine)\n",
    "\n",
    "\n",
    "linesOfTestDataAfterSteming = []\n",
    "for line in linesOfTestDataAfterPreProcessing:\n",
    "    newLine = line\n",
    "    for w in newLine.split():\n",
    "            newLine = newLine.replace(w, st.stem(w)) # for stemming\n",
    "    linesOfTestDataAfterSteming.append(newLine)\n",
    "\n",
    "linesOfTestData = linesOfTestDataAfterSteming\n",
    "\n",
    "print (\"\\n\\nFirst line after cleanup from Test Data: \",linesOfTestData[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21456\n",
      "21379\n",
      "21174\n",
      "21106\n"
     ]
    }
   ],
   "source": [
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(linesOfTrainData, linesOfTestData, test_size= 0.1,train_size= 0.9, random_state=42)\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english')\n",
    "#linesOfTrainData_Transformed =  vectorizer.fit_transform(features_train)\n",
    "linesOfTrainData_Transformed =  vectorizer.fit_transform(linesOfTrainData)\n",
    "\n",
    "print (len(vectorizer.vocabulary_)) # after loading vocab from 1 source\n",
    "print(vectorizer.vocabulary_['younger'])\n",
    "linesOfTrainData_Transformed =  vectorizer.fit_transform(linesOfTestData)\n",
    "print (len(vectorizer.vocabulary_)) # after loading vocab from 2nd source\n",
    "print(vectorizer.vocabulary_['younger'])\n",
    "\n",
    "\n",
    "#linesOfTestData_Transformed = vectorizer.transform(features_test)\n",
    "linesOfTestData_Transformed = vectorizer.transform(linesOfTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['+1\\tthi book lif saver.  help abl go back track trends, answ pedy questions, commun diff tim night newborn.  think on thing everyon requir leav hospital.  went pag newborn version, mov inf version, fin second inf book (third total) right baby turn 1.  see thing must hav baby [...]\\n']\n",
      "-------\n",
      "  (0, 13436)\t0.14380652995\n",
      "  (0, 12286)\t0.151669834287\n",
      "  (0, 13235)\t0.251096266512\n",
      "  (0, 898)\t0.149984374319\n",
      "  (0, 19150)\t0.26806979078\n",
      "  (0, 2055)\t0.0831350167096\n",
      "  (0, 7322)\t0.243571043016\n",
      "  (0, 16701)\t0.150721320458\n",
      "  (0, 5627)\t0.149762694765\n",
      "  (0, 3668)\t0.153496830197\n",
      "  (0, 15946)\t0.327152400334\n",
      "  (0, 8717)\t0.192517434962\n",
      "  (0, 11882)\t0.129196387806\n",
      "  (0, 10758)\t0.364629492777\n",
      "  (0, 11154)\t0.145251646234\n",
      "  (0, 6429)\t0.102601807415\n",
      "  (0, 6026)\t0.28552781051\n",
      "  (0, 1797)\t0.217778738408\n",
      "  (0, 14669)\t0.282995160754\n",
      "  (0, 8695)\t0.329633853779\n",
      "  (0, 15532)\t0.144578324191\n"
     ]
    }
   ],
   "source": [
    "print(linesOfTrainData[:1]) \n",
    "print('-------')\n",
    "print(linesOfTrainData_Transformed[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"perfect new parents. abl keep track baby's feeding, sleep diap chang schedule first two half month lif. mad lif easy doct would ask quest habit right there!\\n\"]\n",
      "-------\n",
      "  (0, 19150)\t0.26806979078\n",
      "  (0, 16701)\t0.150721320458\n",
      "  (0, 15946)\t0.327152400334\n",
      "  (0, 15532)\t0.144578324191\n",
      "  (0, 14669)\t0.282995160754\n",
      "  (0, 13436)\t0.14380652995\n",
      "  (0, 13235)\t0.251096266512\n",
      "  (0, 12286)\t0.151669834287\n",
      "  (0, 11882)\t0.129196387806\n",
      "  (0, 11154)\t0.145251646234\n",
      "  (0, 10758)\t0.364629492777\n",
      "  (0, 8717)\t0.192517434962\n",
      "  (0, 8695)\t0.329633853779\n",
      "  (0, 7322)\t0.243571043016\n",
      "  (0, 6429)\t0.102601807415\n",
      "  (0, 6026)\t0.28552781051\n",
      "  (0, 5627)\t0.149762694765\n",
      "  (0, 3668)\t0.153496830197\n",
      "  (0, 2055)\t0.0831350167096\n",
      "  (0, 1797)\t0.217778738408\n",
      "  (0, 898)\t0.149984374319\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(linesOfTestData[:1])\n",
    "print('-------')\n",
    "print(linesOfTestData_Transformed[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# selector = SelectPercentile(f_classif, percentile=10)\n",
    "# selector.fit(linesOfTrainData_Transformed, labels_train) #labels_train\n",
    "# linesOfTrainData_Transformed = selector.transform(linesOfTrainData_Transformed)\n",
    "# linesOfTestData_Transformed = selector.transform(linesOfTestData_Transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def CalculateCosine(vt,vs):\n",
    "        dotProduct = vt.dot(np.transpose(vS))\n",
    "        lengtht = np.linalg.norm(vt.data)\n",
    "        lengthS = np.linalg.norm(vS.data)\n",
    "\n",
    "        #handle exceptions\n",
    "\n",
    "        if lengthS!=0 and lengtht!=0 :\n",
    "            cosineSimilarityValue= dotProduct/(lengtht*lengthS)\n",
    "        else:\n",
    "            cosineSimilarityValue= 0\n",
    "        return cosineSimilarityValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/sparse/compressed.py:225: SparseEfficiencyWarning: Comparing sparse matrices using == is inefficient, try using != instead.\n",
      "  \" != instead.\", SparseEfficiencyWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@@@\n",
      "#### 0\n",
      "#### 3\n",
      "#### 9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "f = open('TestData/Test/format_out.dat', 'w')\n",
    "for vt in linesOfTestData_Transformed:\n",
    "    cosineSimilarityValues=[]\n",
    "    for vS in linesOfTrainData_Transformed:\n",
    "        cosineSimilarityValue = CalculateCosine(vt,vS)\n",
    "        cosineSimilarityValues.append(cosineSimilarityValue)\n",
    "\n",
    "    kneighbours = heapq.nlargest(3, cosineSimilarityValues)\n",
    "    #kneighbours = sp.sparse.csr_matrix.max(cosineSimilarityValues)\n",
    "\n",
    "    neighbourReviewTypeList = []\n",
    "    neighbourReviewTypeNegative = 0\n",
    "    neighbourReviewTypePositive = 0\n",
    "    print(\"@@@@@\")\n",
    "    for neighbour in kneighbours:\n",
    "        index = cosineSimilarityValues.index(neighbour.data[0])\n",
    "        print(\"####\",index)\n",
    "        if linesOfTrainData[index].strip()[0] == '-':\n",
    "            #neighbourReviewTypeList.append(\"-1\")\n",
    "            neighbourReviewTypeNegative+=1\n",
    "        elif linesOfTrainData[index].strip()[0] == '+':\n",
    "            #neighbourReviewTypeList.append(\"+1\")\n",
    "            neighbourReviewTypePositive+=1\n",
    "\n",
    "\n",
    "    if neighbourReviewTypeNegative > neighbourReviewTypePositive:\n",
    "        f.write('-1\\n')\n",
    "    else:\n",
    "        f.write('+1\\n')\n",
    "\n",
    "print(\"-----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
