{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import scipy as sp\n",
    "from scipy import spatial\n",
    "\n",
    "import matplotlib.pyplot as plt # side-stepping mpl backend\n",
    "\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import pairwise\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn import cross_validation\n",
    "import heapq\n",
    "import string\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "st = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18506\n",
      "18506\n",
      "18506\n"
     ]
    }
   ],
   "source": [
    "with open(\"TestData/train.dat\", \"r\") as fh:\n",
    "    #with open(\"TestData/Test/training_out.dat\", \"r\") as fh:\n",
    "    linesOfTrainData = fh.readlines()\n",
    "print(len(linesOfTrainData))\n",
    "\n",
    "#with open(\"TestData/format.dat\", \"r\") as fh:\n",
    "with open(\"TestData/Test/format_out.dat\", \"r\") as fh:\n",
    "    linesOfFormat = fh.readlines()\n",
    "print(len(linesOfFormat))\n",
    "\n",
    "with open(\"TestData/test.dat\", \"r\") as fh:\n",
    "#with open(\"TestData/Test/test_out.dat\", \"r\") as fh:\n",
    "    linesOfTestData = fh.readlines()\n",
    "print(len(linesOfTestData))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First line before cleanup from Training Data:  +1\tThis book is such a life saver.  It has been so helpful to be able to go back to track trends, answer pediatrician questions, or communicate with each other when you are up at different times of the night with a newborn.  I think it is one of those things that everyone should be required to have before they leave the hospital.  We went through all the pages of the newborn version, then moved to the infant version, and will finish up the second infant book (third total) right as our baby turns 1.  See other things that are must haves for baby at [...]\n",
      "\n",
      "\n",
      "\n",
      "First line after cleanup from Training Data:  +1 book lif saver. help abl go back track trends, answ pedy questions, commun diff tim night newborn. think on thing everyon requir leav hospital. went pag newborn version, mov inf version, fin second inf book (third total) right baby turn 1. see thing must hav baby [...]\n"
     ]
    }
   ],
   "source": [
    "# ##stopwords and stemming for Training\n",
    "\n",
    "# print (\"First line before cleanup from Training Data: \",linesOfTrainData[0])\n",
    "\n",
    "# stops = set(stopwords.words('english'))\n",
    "\n",
    "# linesOfTrainDataAfterPreProcessing=[]\n",
    "# for line in linesOfTrainData:\n",
    "#     newLine = []\n",
    "#     for w in line.split():\n",
    "#         if w.lower()not in stops:\n",
    "#             newLine.append(w)     #for stopwords  \n",
    "#     linesOfTrainDataAfterPreProcessing.append(\" \".join(newLine))\n",
    "\n",
    "\n",
    "# linesOfTrainDataAfterSteming = []\n",
    "# for line in linesOfTrainDataAfterPreProcessing:\n",
    "#     newLine = line\n",
    "#     for w in newLine.split():\n",
    "#             newLine = newLine.replace(w, st.stem(w)) # for stemming\n",
    "#     linesOfTrainDataAfterSteming.append(newLine)\n",
    "    \n",
    "# #Not working    \n",
    "# linesOfTrainDataAfterStemingWithoutPunctuation = []\n",
    "# for line in linesOfTrainDataAfterSteming:\n",
    "#     newLine = line\n",
    "#     for w in newLine.split():\n",
    "#          if w in string.punctuation:\n",
    "#             newLine = newLine.translate(string.punctuation)\n",
    "#             #newLine = newLine.replace(w,re.sub(r'[^\\w\\s]()','',w)) # for Punctuation \n",
    "#     linesOfTrainDataAfterStemingWithoutPunctuation.append(newLine)    \n",
    "\n",
    "\n",
    "# linesOfTrainData = linesOfTrainDataAfterStemingWithoutPunctuation\n",
    "\n",
    "# print (\"\\n\\nFirst line after cleanup from Training Data: \",linesOfTrainData[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First line before cleanup from Test Data:  Perfect for new parents. We were able to keep track of baby's feeding, sleep and diaper change schedule for the first two and a half months of her life. Made life easier when the doctor would ask questions about habits because we had it all right there!\n",
      "\n",
      "\n",
      "\n",
      "First line after cleanup from Test Data:  perfect new parents. abl keep track baby's feeding, sleep diap chang schedule first two half month lif. mad lif easy doct would ask quest habit right there!\n"
     ]
    }
   ],
   "source": [
    "# ##stopwords and stemming for Testdata\n",
    "\n",
    "# print (\"First line before cleanup from Test Data: \",linesOfTestData[0])\n",
    "\n",
    "# stops = set(stopwords.words('english'))\n",
    "\n",
    "# linesOfTestDataAfterPreProcessing=[]\n",
    "# for line in linesOfTestData:\n",
    "#     newLine = []\n",
    "#     for w in line.split():\n",
    "#         if w.lower()not in stops:\n",
    "#             newLine.append(w)       \n",
    "#     linesOfTestDataAfterPreProcessing.append(\" \".join(newLine)) # for identifting words\n",
    "    \n",
    "\n",
    "# linesOfTestDataAfterSteming = []\n",
    "# for line in linesOfTestDataAfterPreProcessing:\n",
    "#     newLine = line\n",
    "#     for w in newLine.split():\n",
    "#             newLine = newLine.replace(w, st.stem(w)) # for stemming\n",
    "#     linesOfTestDataAfterSteming.append(newLine)\n",
    "    \n",
    "# linesOfTestDataAfterStemingWithoutPunctuation = []\n",
    "# for line in linesOfTestDataAfterSteming:\n",
    "#     newLine = line\n",
    "#     for w in newLine.split():\n",
    "#          if w in string.punctuation:\n",
    "#             newLine = newLine.translate(string.punctuation)\n",
    "#             #newLine = newLine.replace(w,re.sub(r'[^\\w\\s]()','',w)) # for Punctuation \n",
    "#     linesOfTestDataAfterStemingWithoutPunctuation.append(newLine)\n",
    "    \n",
    "    \n",
    "\n",
    "# linesOfTestData = linesOfTestDataAfterStemingWithoutPunctuation\n",
    "\n",
    "# print (\"\\n\\nFirst line after cleanup from Test Data: \",linesOfTestData[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 63293.\n"
     ]
    }
   ],
   "source": [
    "# # get a frequency count for all words in the Training docs\n",
    "\n",
    "\n",
    "\n",
    "# wordsInTrainingSet = set()\n",
    "# for d in linesOfTrainData:\n",
    "#     for w in d.split():\n",
    "#         if w == \"+1\" or w == \"-1\":\n",
    "#             continue\n",
    "#         else:\n",
    "#             if w not in wordsInTrainingSet:\n",
    "#                 wordsInTrainingSet.add(w)\n",
    "#                 #wordsList.append(w)\n",
    "#             #else:\n",
    "#              #   wordsInTrainingSet[w] += 1\n",
    "# print(\"Number of unique words: %d.\" % len(wordsInTrainingSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 63059.\n"
     ]
    }
   ],
   "source": [
    "# # get a frequency count for all words in the Test docs\n",
    "# wordsInTestSet  = set()\n",
    "# for d in linesOfTestData:\n",
    "#     for w in d.split():\n",
    "#         if w not in wordsInTestSet:\n",
    "#             wordsInTestSet.add(w)\n",
    "#             #wordsList.append(w)\n",
    "#         #else:\n",
    "#          #   wordsInTestSet[w] += 1\n",
    "# print(\"Number of unique words: %d.\" % len(wordsInTestSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 25646.\n"
     ]
    }
   ],
   "source": [
    "# wordsInSet = set()\n",
    "# wordsList= []\n",
    "\n",
    "# wordsInSet =  set.intersection(wordsInTrainingSet,wordsInTestSet)\n",
    "# wordsList = list(wordsInSet)\n",
    "\n",
    "# print(\"Number of unique words: %d.\" % len(wordsInSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "12823\n"
     ]
    }
   ],
   "source": [
    "# from collections import Counter\n",
    "# c = Counter(wordsInSet)\n",
    "\n",
    "# top_percentile = 0.5 # 0.2 Precentile\n",
    "# features = c.most_common(int(round(len(c)*top_percentile)))\n",
    "# features_counts = len(features)\n",
    "\n",
    "# print(type(features))\n",
    "# print(features_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    " #vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1,3), min_df = 50, stop_words = 'english', vocabulary=features)\n",
    "  \n",
    "vectorizer = CountVectorizer(analyzer='word', lowercase = True, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "linesOfTrainData_Transformed = vectorizer.fit_transform(linesOfTrainData)\n",
    "#print(linesOfTrainData_Transformed[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "linesOfTestData_Transformed = vectorizer.transform(linesOfTestData)\n",
    "#print(test_data_features[:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12823"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names() \n",
    "len(feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def CalculateCosine(vt,vs):\n",
    "        cosineSimilarityValue = cosine_similarity(vt,vs)\n",
    "        return cosineSimilarityValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cosineSimilarityValue = CalculateCosine(linesOfTestData_Transformed,linesOfTrainData_Transformed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count :  18506\n",
      "--The End--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f = open('TestData/Test/format_out.dat', 'w')\n",
    "count = 0\n",
    "for row in cosineSimilarityValue:\n",
    "\n",
    "    \n",
    "    #kneighbours = heapq.nlargest(5, row)\n",
    "    k=72\n",
    "    partitioned_row_byindex = np.argpartition(-row, k)  \n",
    "    similar_index = partitioned_row_byindex[:k]\n",
    "    \n",
    "    #print(similar_index)\n",
    "    \n",
    "    neighbourReviewTypeList = []\n",
    "    neighbourReviewTypeNegative = 0\n",
    "    neighbourReviewTypePositive = 0\n",
    "    \n",
    "    #print(\"@@@@@\",+count)\n",
    "    for index in similar_index:\n",
    "\n",
    "        if linesOfTrainData[index].strip()[0] == '-':\n",
    "            #neighbourReviewTypeList.append(\"-1\")\n",
    "            neighbourReviewTypeNegative+=1\n",
    "        elif linesOfTrainData[index].strip()[0] == '+':\n",
    "            #neighbourReviewTypeList.append(\"+1\")\n",
    "            neighbourReviewTypePositive+=1\n",
    "            \n",
    "    \n",
    "    if neighbourReviewTypeNegative > neighbourReviewTypePositive:\n",
    "        f.write('-1\\n')\n",
    "        count+=1\n",
    "    else:\n",
    "        f.write('+1\\n')\n",
    "        count+=1\n",
    "\n",
    "print(\"count : \",count)\n",
    "print(\"--The End--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
